{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/andybryant/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import stopwords, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = set(stopwords.words())\n",
    "nltk_words = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_from_txt(filepath):\n",
    "    '''Helper function for opening, reading, and concerting .txt file of vectors. \n",
    "    Returns a dictionary of the embeddings vectors.'''\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter=' ',quoting=csv.QUOTE_NONE)\n",
    "        embeddings_dict = {line[0]: np.array(list(map(float, line[1:]))) for line in reader}\n",
    "    return embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_keys(keys):\n",
    "    '''Helper function for filtering stopwords and non-english words from a list of keys.\n",
    "    Returns a list of strings.'''\n",
    "    words = []\n",
    "    for key in keys:\n",
    "        if key not in nltk_stopwords and key in nltk_words:\n",
    "            words.append(key)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_dict(old_dict, words_to_keep):\n",
    "    '''Helper function for filtering a dictionary, keeping a specific list of words.\n",
    "    Returns a dictionary with words as keys and vectors as values.'''\n",
    "    new_dict = dict()\n",
    "    for w in words_to_keep:\n",
    "        val = old_dict.get(w)\n",
    "        # If dictionary has the word as a key, store its value\n",
    "        if val is not None:\n",
    "            new_dict[w] = val\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_txt(filepath):\n",
    "    '''Helper function for generating dataframe with words as the index and the dimensions as columns.\n",
    "    Returns that dataframe.'''\n",
    "    vec_dict = get_dict_from_txt(filepath)\n",
    "    vec_keys = list(vec_dict.keys())\n",
    "    vec_words = get_words_from_keys(vec_keys)\n",
    "    vec_dict_filtered = get_filtered_dict(vec_dict, vec_words)\n",
    "    return pd.DataFrame.from_dict(vec_dict_filtered, orient=\"index\", dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe\n",
    "# I got this model from here: http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
    "# Trained on 42 billion words\n",
    "glove_filepath = \"./data/glove_top_200000.txt\"\n",
    "df_glove = get_df_from_txt(glove_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I got word2vec from the google repo and loaded it using gensim\n",
    "# The first header line had to be removed\n",
    "# from gensim.models.word2vec import Word2Vec\n",
    "# from gensim.models import KeyedVectors\n",
    "# model = KeyedVectors.load_word2vec_format('/Users/andybryant/Downloads/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "# model.wv.save_word2vec_format('googlenews.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2vec\n",
    "google_filepath = \"./data/googlenews_top_200000.txt\"\n",
    "df_google = get_df_from_txt(google_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastText\n",
    "# I got this model from here: https://fasttext.cc/docs/en/english-vectors.html\n",
    "# It's the wiki-news 1m vectors dataset\n",
    "ft_filepath = \"./data/fasttext_top_200000.txt\"\n",
    "df_ft = get_df_from_txt(ft_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num words that the sets share: 28633\n",
      "Num words that the sets do not share: 13283\n"
     ]
    }
   ],
   "source": [
    "# Make sets of the different words\n",
    "glove_words_final = set(df_glove.index.tolist())\n",
    "google_words_final = set(df_google.index.tolist())\n",
    "ft_words_final = set(df_ft.index.tolist())\n",
    "# Get their intersection - the words that appear3 in all of them \n",
    "intersection = glove_words_final.intersection(google_words_final, ft_words_final)\n",
    "# Get their union - the words that appear in at least one of them\n",
    "union = glove_words_final.union(google_words_final, ft_words_final)\n",
    "# The ones that do not appear in all three\n",
    "diff = union.symmetric_difference(intersection)\n",
    "print(f'Num words that the sets share: {len(intersection)}')\n",
    "print(f'Num words that the sets do not share: {len(diff)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with words that are not present in every dataframe\n",
    "df_glove.drop(diff, errors='ignore', inplace=True)\n",
    "df_google.drop(diff, errors='ignore', inplace=True)\n",
    "df_ft.drop(diff, errors='ignore', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a multindex dataframe with all of the intersection words in descending order of num appearances\n",
    "data = {'glove' : df_glove, 'word2vec' : df_google, 'fasttext': df_ft}\n",
    "midx = pd.MultiIndex.from_product([list(df_glove.index), data.keys()]) \n",
    "res = pd.concat(data, axis=0, keys=data.keys()).swaplevel(i=0,j=1,axis=0)\n",
    "df_all_vectors = res.sort_index(level=0).reindex(midx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">I</th>\n",
       "      <th>glove</th>\n",
       "      <td>0.194100</td>\n",
       "      <td>0.226030</td>\n",
       "      <td>-0.437640</td>\n",
       "      <td>-0.113870</td>\n",
       "      <td>-0.072725</td>\n",
       "      <td>0.360030</td>\n",
       "      <td>-0.063595</td>\n",
       "      <td>0.056585</td>\n",
       "      <td>-0.094555</td>\n",
       "      <td>2.356100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194080</td>\n",
       "      <td>0.181530</td>\n",
       "      <td>0.068346</td>\n",
       "      <td>0.133040</td>\n",
       "      <td>0.291810</td>\n",
       "      <td>-0.036109</td>\n",
       "      <td>0.112210</td>\n",
       "      <td>0.091957</td>\n",
       "      <td>0.386320</td>\n",
       "      <td>0.117360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec</th>\n",
       "      <td>0.079102</td>\n",
       "      <td>-0.005035</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.212891</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>-0.014709</td>\n",
       "      <td>-0.035400</td>\n",
       "      <td>-0.077637</td>\n",
       "      <td>0.040771</td>\n",
       "      <td>0.114746</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125977</td>\n",
       "      <td>0.153320</td>\n",
       "      <td>-0.306641</td>\n",
       "      <td>-0.078613</td>\n",
       "      <td>-0.086426</td>\n",
       "      <td>-0.114746</td>\n",
       "      <td>-0.029297</td>\n",
       "      <td>-0.006775</td>\n",
       "      <td>0.042725</td>\n",
       "      <td>-0.103516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fasttext</th>\n",
       "      <td>-0.145700</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>-0.016800</td>\n",
       "      <td>0.112700</td>\n",
       "      <td>-0.141800</td>\n",
       "      <td>-0.035700</td>\n",
       "      <td>-0.030300</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.241300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>-0.095200</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>-0.046800</td>\n",
       "      <td>-0.056300</td>\n",
       "      <td>-0.007300</td>\n",
       "      <td>-0.044400</td>\n",
       "      <td>0.281300</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>-0.076200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">The</th>\n",
       "      <th>glove</th>\n",
       "      <td>-0.067679</td>\n",
       "      <td>0.094515</td>\n",
       "      <td>-0.251730</td>\n",
       "      <td>-0.242680</td>\n",
       "      <td>-0.610930</td>\n",
       "      <td>-0.053369</td>\n",
       "      <td>-0.160110</td>\n",
       "      <td>0.065661</td>\n",
       "      <td>0.387110</td>\n",
       "      <td>1.731900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.536040</td>\n",
       "      <td>0.250090</td>\n",
       "      <td>-0.024844</td>\n",
       "      <td>0.029295</td>\n",
       "      <td>0.031403</td>\n",
       "      <td>0.045725</td>\n",
       "      <td>0.294420</td>\n",
       "      <td>-0.184880</td>\n",
       "      <td>-0.035434</td>\n",
       "      <td>-0.060077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec</th>\n",
       "      <td>-0.172852</td>\n",
       "      <td>0.279297</td>\n",
       "      <td>0.106934</td>\n",
       "      <td>-0.158203</td>\n",
       "      <td>-0.084473</td>\n",
       "      <td>0.059082</td>\n",
       "      <td>0.040771</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.259766</td>\n",
       "      <td>0.180664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017700</td>\n",
       "      <td>-0.128906</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.014771</td>\n",
       "      <td>-0.052979</td>\n",
       "      <td>-0.203125</td>\n",
       "      <td>0.061768</td>\n",
       "      <td>0.123047</td>\n",
       "      <td>0.129883</td>\n",
       "      <td>-0.182617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">conditionality</th>\n",
       "      <th>word2vec</th>\n",
       "      <td>-0.025635</td>\n",
       "      <td>0.226562</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.458984</td>\n",
       "      <td>-0.202148</td>\n",
       "      <td>0.261719</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.110352</td>\n",
       "      <td>0.275391</td>\n",
       "      <td>-0.202148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.566406</td>\n",
       "      <td>0.419922</td>\n",
       "      <td>-0.060059</td>\n",
       "      <td>-0.188477</td>\n",
       "      <td>0.157227</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>0.065918</td>\n",
       "      <td>0.192383</td>\n",
       "      <td>-0.233398</td>\n",
       "      <td>-0.188477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fasttext</th>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>-0.243500</td>\n",
       "      <td>-0.125200</td>\n",
       "      <td>-0.093600</td>\n",
       "      <td>-0.043900</td>\n",
       "      <td>0.264200</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>0.302500</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162700</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>-0.235200</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>-0.305800</td>\n",
       "      <td>-0.085900</td>\n",
       "      <td>-0.004600</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>-0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dockyard</th>\n",
       "      <th>glove</th>\n",
       "      <td>0.743320</td>\n",
       "      <td>-0.477220</td>\n",
       "      <td>0.036977</td>\n",
       "      <td>-0.361620</td>\n",
       "      <td>-0.138810</td>\n",
       "      <td>-0.878380</td>\n",
       "      <td>-0.374230</td>\n",
       "      <td>0.022724</td>\n",
       "      <td>-0.060998</td>\n",
       "      <td>0.077551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357470</td>\n",
       "      <td>-0.645000</td>\n",
       "      <td>0.280570</td>\n",
       "      <td>0.120660</td>\n",
       "      <td>-0.524980</td>\n",
       "      <td>0.308980</td>\n",
       "      <td>-0.132400</td>\n",
       "      <td>0.277940</td>\n",
       "      <td>-0.958800</td>\n",
       "      <td>-0.429020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec</th>\n",
       "      <td>0.147461</td>\n",
       "      <td>-0.010132</td>\n",
       "      <td>-0.111328</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>-0.017944</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>-0.104980</td>\n",
       "      <td>0.255859</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.241211</td>\n",
       "      <td>-0.092285</td>\n",
       "      <td>-0.096191</td>\n",
       "      <td>0.027466</td>\n",
       "      <td>-0.003998</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>-0.269531</td>\n",
       "      <td>-0.010254</td>\n",
       "      <td>-0.103027</td>\n",
       "      <td>-0.029785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fasttext</th>\n",
       "      <td>0.012100</td>\n",
       "      <td>-0.279200</td>\n",
       "      <td>0.144200</td>\n",
       "      <td>-0.163300</td>\n",
       "      <td>-0.024500</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.298800</td>\n",
       "      <td>-0.429000</td>\n",
       "      <td>-0.178500</td>\n",
       "      <td>-0.046900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>-0.290500</td>\n",
       "      <td>-0.005400</td>\n",
       "      <td>-0.031500</td>\n",
       "      <td>0.219600</td>\n",
       "      <td>-0.127100</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>-0.049300</td>\n",
       "      <td>-0.100400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85899 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0         1         2         3         4    \\\n",
       "I              glove     0.194100  0.226030 -0.437640 -0.113870 -0.072725   \n",
       "               word2vec  0.079102 -0.005035  0.111816  0.212891  0.130859   \n",
       "               fasttext -0.145700  0.095000  0.040900 -0.016800  0.112700   \n",
       "The            glove    -0.067679  0.094515 -0.251730 -0.242680 -0.610930   \n",
       "               word2vec -0.172852  0.279297  0.106934 -0.158203 -0.084473   \n",
       "...                           ...       ...       ...       ...       ...   \n",
       "conditionality word2vec -0.025635  0.226562  0.144531  0.458984 -0.202148   \n",
       "               fasttext  0.038000  0.048500 -0.243500 -0.125200 -0.093600   \n",
       "dockyard       glove     0.743320 -0.477220  0.036977 -0.361620 -0.138810   \n",
       "               word2vec  0.147461 -0.010132 -0.111328  0.024414  0.163086   \n",
       "               fasttext  0.012100 -0.279200  0.144200 -0.163300 -0.024500   \n",
       "\n",
       "                              5         6         7         8         9    \\\n",
       "I              glove     0.360030 -0.063595  0.056585 -0.094555  2.356100   \n",
       "               word2vec -0.014709 -0.035400 -0.077637  0.040771  0.114746   \n",
       "               fasttext -0.141800 -0.035700 -0.030300  0.022300  0.241300   \n",
       "The            glove    -0.053369 -0.160110  0.065661  0.387110  1.731900   \n",
       "               word2vec  0.059082  0.040771  0.002548  0.259766  0.180664   \n",
       "...                           ...       ...       ...       ...       ...   \n",
       "conditionality word2vec  0.261719  0.339844  0.110352  0.275391 -0.202148   \n",
       "               fasttext -0.043900  0.264200 -0.000100  0.302500  0.008600   \n",
       "dockyard       glove    -0.878380 -0.374230  0.022724 -0.060998  0.077551   \n",
       "               word2vec -0.017944 -0.038086 -0.104980  0.255859  0.021118   \n",
       "               fasttext  0.020300  0.298800 -0.429000 -0.178500 -0.046900   \n",
       "\n",
       "                         ...       290       291       292       293  \\\n",
       "I              glove     ... -0.194080  0.181530  0.068346  0.133040   \n",
       "               word2vec  ... -0.125977  0.153320 -0.306641 -0.078613   \n",
       "               fasttext  ...  0.248500 -0.095200  0.045000 -0.046800   \n",
       "The            glove     ... -0.536040  0.250090 -0.024844  0.029295   \n",
       "               word2vec  ... -0.017700 -0.128906  0.021973  0.014771   \n",
       "...                      ...       ...       ...       ...       ...   \n",
       "conditionality word2vec  ... -0.566406  0.419922 -0.060059 -0.188477   \n",
       "               fasttext  ...  0.162700  0.138500 -0.235200  0.045100   \n",
       "dockyard       glove     ...  0.357470 -0.645000  0.280570  0.120660   \n",
       "               word2vec  ... -0.241211 -0.092285 -0.096191  0.027466   \n",
       "               fasttext  ...  0.056600  0.121100 -0.290500 -0.005400   \n",
       "\n",
       "                              294       295       296       297       298  \\\n",
       "I              glove     0.291810 -0.036109  0.112210  0.091957  0.386320   \n",
       "               word2vec -0.086426 -0.114746 -0.029297 -0.006775  0.042725   \n",
       "               fasttext -0.056300 -0.007300 -0.044400  0.281300  0.154100   \n",
       "The            glove     0.031403  0.045725  0.294420 -0.184880 -0.035434   \n",
       "               word2vec -0.052979 -0.203125  0.061768  0.123047  0.129883   \n",
       "...                           ...       ...       ...       ...       ...   \n",
       "conditionality word2vec  0.157227  0.090820  0.065918  0.192383 -0.233398   \n",
       "               fasttext -0.305800 -0.085900 -0.004600  0.166400  0.048500   \n",
       "dockyard       glove    -0.524980  0.308980 -0.132400  0.277940 -0.958800   \n",
       "               word2vec -0.003998  0.006927 -0.269531 -0.010254 -0.103027   \n",
       "               fasttext -0.031500  0.219600 -0.127100  0.069300 -0.049300   \n",
       "\n",
       "                              299  \n",
       "I              glove     0.117360  \n",
       "               word2vec -0.103516  \n",
       "               fasttext -0.076200  \n",
       "The            glove    -0.060077  \n",
       "               word2vec -0.182617  \n",
       "...                           ...  \n",
       "conditionality word2vec -0.188477  \n",
       "               fasttext -0.013900  \n",
       "dockyard       glove    -0.429020  \n",
       "               word2vec -0.029785  \n",
       "               fasttext -0.100400  \n",
       "\n",
       "[85899 rows x 300 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Voila! A dataframe with all of the words and their corresponding vectors in descending order or\n",
    "# num occurrences for glove, word2vec, and fasttext.\n",
    "df_all_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_vectors.to_csv('./output/all_vectors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_vectors.to_pickle('./output/all_vectors.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
